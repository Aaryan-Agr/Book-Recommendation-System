{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aaryan-Agr/Book-Recommendation-System/blob/main/BookRecommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "saDBafKhnu2J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "!pip install nltk\n",
        "import kagglehub\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "nltk.download('all')\n",
        "path = kagglehub.dataset_download(\"arashnic/book-recommendation-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "''' drive.mount('/content/drive')\n",
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download arashnic/book-recommendation-dataset\n",
        "! unzip book-recommendation-dataset.zip '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iirXLpKazd-p"
      },
      "outputs": [],
      "source": [
        "books = pd.read_csv(\"/root/.cache/kagglehub/datasets/arashnic/book-recommendation-dataset/versions/3/Books.csv\", low_memory = False)\n",
        "ratings = pd.read_csv(\"/root/.cache/kagglehub/datasets/arashnic/book-recommendation-dataset/versions/3/Ratings.csv\", low_memory = False)\n",
        "users = pd.read_csv(\"/root/.cache/kagglehub/datasets/arashnic/book-recommendation-dataset/versions/3/Users.csv\", low_memory = False)\n",
        "\n",
        "#removing unwanted features\n",
        "books = books[['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher']]\n",
        "#remove null values\n",
        "books.dropna(inplace=True)\n",
        "\n",
        "# Function to clean data (lowercase and remove spaces)\n",
        "def clean_data(x):\n",
        "    if isinstance(x, str):\n",
        "        return str.lower(x.replace(\" \", \"\"))\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Apply data cleaning to the metadata columns\n",
        "features = ['Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher']\n",
        "for feature in features:\n",
        "    books[feature] = books[feature].apply(clean_data)\n",
        "\n",
        "merged = ratings.merge(books, on='ISBN') #Merge Ratings and Books\n",
        "x = merged.groupby('User-ID').count()['Book-Rating'] >= 100 #Filter out users with less than 100 book ratings\n",
        "importantUsers = x[x].index #Get Important users\n",
        "filteredRatings = merged[merged['User-ID'].isin(importantUsers)]\n",
        "y = filteredRatings.groupby('Book-Title').count()['Book-Rating'] >= 25 #Filter out books with less that 25 unique ratings\n",
        "importantBooks = y[y].index #Get important books\n",
        "finalRatings = filteredRatings[filteredRatings['Book-Title'].isin(importantBooks)] #Only include important books\n",
        "userItem = finalRatings.pivot_table(index='Book-Title', columns = 'User-ID', values = 'Book-Rating') #Make user Item Matrix\n",
        "userItem.fillna(0, inplace=True) #Fill missing values with 0\n",
        "simScore = cosine_similarity(userItem) #Get similarity Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tvpExOikX9p"
      },
      "outputs": [],
      "source": [
        "def contentFiltering(books_df, test_title, top_n=10):\n",
        "    \"\"\" Generates book recommendations based on cosine similarity. \"\"\"\n",
        "    # Clean the input title\n",
        "    title = clean_data(test_title)\n",
        "    # Combine metadata into a single 'soup' column\n",
        "    books_df['soup'] = (\n",
        "        books_df['Book-Title'].fillna('') + ' ' +\n",
        "        books_df['Book-Author'].fillna('') + ' ' +\n",
        "        books_df['Year-Of-Publication'].fillna('').astype(str)\n",
        "    )\n",
        "    # Vectorize the 'soup' column\n",
        "    count_vectorizer = CountVectorizer(stop_words='english', max_features=10000)\n",
        "    count_matrix = count_vectorizer.fit_transform(books_df['soup'])\n",
        "    # Train NearestNeighbors model\n",
        "    nn_model = NearestNeighbors(n_neighbors=top_n + 1, metric='cosine', algorithm='brute')\n",
        "    nn_model.fit(count_matrix)\n",
        "    # Create a reverse mapping of indices and book titles\n",
        "    books_df = books_df.reset_index(drop=True)\n",
        "    indices = pd.Series(books_df.index, index=books_df['Book-Title']).drop_duplicates()\n",
        "    # Check if the title exists in indices\n",
        "    if test_title not in indices:\n",
        "        return f\"Book '{test_title}' not found in the dataset.\"\n",
        "    idx = indices[test_title]\n",
        "    # Find the nearest neighbors\n",
        "    distances, neighbors = nn_model.kneighbors(count_matrix[idx], n_neighbors=top_n + 1)\n",
        "    # Generate recommendations\n",
        "    recommendations = []\n",
        "    for i in range(1, len(neighbors[0])):  # Start from 1 to exclude the input book itself\n",
        "        neighbor_idx = neighbors[0][i]\n",
        "        similarity_score = 1 - distances[0][i]  # Convert distance to similarity\n",
        "        book_title = books_df['Book-Title'].iloc[neighbor_idx]\n",
        "        recommendations.append((book_title, similarity_score))\n",
        "    return recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "941juYbVAoJw",
        "outputId": "17b21d18-0b73-43dc-95c5-e1b6d2c0c67b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Books similar to '1984':\n",
            "1984 (Similarity: 0.82)\n",
            "nineteeneighty-four:thefacsimileoftheextantmanuscript (Similarity: 0.82)\n",
            "1984 (Similarity: 0.82)\n",
            "1984(spanishlanguageedition) (Similarity: 0.71)\n",
            "1984 (Similarity: 0.67)\n"
          ]
        }
      ],
      "source": [
        "test_title = \"1984\"\n",
        "recommendations = contentFiltering(books, test_title, top_n=5)\n",
        "\n",
        "# Display recommendations\n",
        "if isinstance(recommendations, list):\n",
        "    print(f\"Books similar to '{test_title}':\")\n",
        "    for book, score in recommendations:\n",
        "        print(f\"{book} (Similarity: {score:.2f})\")\n",
        "else:\n",
        "    print(recommendations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5fZYju7rb2V"
      },
      "outputs": [],
      "source": [
        "def colabfiltering(book, top_n):\n",
        "    ann_model = NearestNeighbors(n_neighbors=top_n+1, metric='cosine', algorithm='brute')\n",
        "    ann_model.fit(userItem)\n",
        "    book_vector = userItem.loc[book_name].values.reshape(1, -1)\n",
        "    distances, indices = ann_model.kneighbors(book_vector)\n",
        "    recommendations = []\n",
        "    for i in range(1, len(indices[0])):\n",
        "        similar_book = userItem.index[indices[0][i]]\n",
        "        similarity_score = 1 - distances[0][i]\n",
        "        recommendations.append((similar_book, similarity_score))\n",
        "    return recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "654P8xbRA5Qv",
        "outputId": "daaaa183-b48e-44eb-83dd-9c7e2ea500cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Books similar to '1984':\n",
            "animalfarm (Similarity: 0.23)\n",
            "lyingawake (Similarity: 0.23)\n",
            "waiting (Similarity: 0.21)\n",
            "bravenewworld (Similarity: 0.21)\n",
            "slaughterhousefiveorthechildren'scrusade:adutydancewithdeath (Similarity: 0.20)\n",
            "therestaurantattheendoftheuniverse(hitchhiker'strilogy(paperback)) (Similarity: 0.19)\n",
            "sarah'swindow (Similarity: 0.19)\n",
            "awakening (Similarity: 0.18)\n",
            "thehandmaid'stale (Similarity: 0.18)\n",
            "rollofthunder,hearmycry (Similarity: 0.18)\n"
          ]
        }
      ],
      "source": [
        "book_name = \"1984\"\n",
        "recommendations = colabfiltering(book_name, 10)\n",
        "\n",
        "if isinstance(recommendations, list):\n",
        "    print(f\"Books similar to '{book_name}':\")\n",
        "    for book, score in recommendations:\n",
        "        print(f\"{book} (Similarity: {score:.2f})\")\n",
        "else:\n",
        "    print(recommendations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7pyoAczE2D7"
      },
      "outputs": [],
      "source": [
        "def normalize(scores):\n",
        "    min_score = min(scores.values())\n",
        "    max_score = max(scores.values())\n",
        "    if max_score - min_score == 0:\n",
        "        return {item: 1 for item in scores}\n",
        "    return {item: (score - min_score) / (max_score - min_score) for item, score in scores.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQBSRLQBwcAV"
      },
      "outputs": [],
      "source": [
        "# Hybrid recommendation\n",
        "def hybrid_recommendations(user_id, book_title, content_weight=0.5, collaborative_weight=0.5, num_recommendations=10):\n",
        "    content_recs = contentFiltering(books, book_title, num_recommendations)\n",
        "    collaborative_recs = colabfiltering(user_id, num_recommendations)\n",
        "\n",
        "    combined_scores = {}\n",
        "    for book, score in content_recs:\n",
        "        combined_scores[book] = combined_scores.get(book, 0) + score * content_weight\n",
        "    for book, score in collaborative_recs:\n",
        "        combined_scores[book] = combined_scores.get(book, 0) + score * collaborative_weight\n",
        "\n",
        "    combined_scores = normalize(combined_scores)\n",
        "\n",
        "    sorted_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
        "    return sorted_recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2ojCu5Kgxb2S",
        "outputId": "721a07b3-129f-4d66-8c60-c58ad70a2433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hybrid Recommendations:\n",
            "1984 (Hybrid Score: 1.00)\n",
            "animalfarm (Hybrid Score: 0.56)\n",
            "lyingawake (Hybrid Score: 0.30)\n",
            "waiting (Hybrid Score: 0.26)\n",
            "bravenewworld (Hybrid Score: 0.26)\n",
            "slaughterhousefiveorthechildren'scrusade:adutydancewithdeath (Hybrid Score: 0.24)\n",
            "therestaurantattheendoftheuniverse(hitchhiker'strilogy(paperback)) (Hybrid Score: 0.23)\n",
            "sarah'swindow (Hybrid Score: 0.22)\n",
            "awakening (Hybrid Score: 0.21)\n",
            "thehandmaid'stale (Hybrid Score: 0.21)\n",
            "rollofthunder,hearmycry (Hybrid Score: 0.21)\n",
            "thecatcherintherye (Hybrid Score: 0.20)\n",
            "lordoftheflies (Hybrid Score: 0.20)\n",
            "biblioholism:theliteraryaddiction (Hybrid Score: 0.20)\n",
            "perfume:thestoryofamurderer(vintageinternational) (Hybrid Score: 0.20)\n",
            "thevampirelestat(vampirechronicles,bookii) (Hybrid Score: 0.19)\n",
            "timeline (Hybrid Score: 0.19)\n",
            "lookatme (Hybrid Score: 0.18)\n",
            "orangesarenottheonlyfruit (Hybrid Score: 0.18)\n",
            "wordfreak:heartbreak,triumph,genius,andobsessionintheworldofcompetitivescrabbleplayers (Hybrid Score: 0.18)\n"
          ]
        }
      ],
      "source": [
        "test_user_id = 277427\n",
        "test_book_title = \"1984\"\n",
        "test_content_weight = 0.1\n",
        "test_collaborative_weight = 0.9\n",
        "test_num_recommendations = 20\n",
        "\n",
        "recommendations = hybrid_recommendations(\n",
        "    test_user_id,\n",
        "    test_book_title,\n",
        "    content_weight=test_content_weight,\n",
        "    collaborative_weight=test_collaborative_weight,\n",
        "    num_recommendations=test_num_recommendations\n",
        ")\n",
        "\n",
        "print(\"Hybrid Recommendations:\")\n",
        "for book, score in recommendations:\n",
        "    print(f\"{book} (Hybrid Score: {score:.2f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm3hW3bRqQqH"
      },
      "outputs": [],
      "source": [
        "#3 Evaluation & Experiments\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def compare_baseline(user_item_matrix, test_indices):\n",
        "    global_mean = user_item_matrix.values[user_item_matrix > 0].mean()\n",
        "    user_means = user_item_matrix.mean(axis=1)\n",
        "    item_means = user_item_matrix.mean(axis=0)\n",
        "\n",
        "    actual_ratings = []\n",
        "    global_predictions = []\n",
        "    user_predictions = []\n",
        "    item_predictions = []\n",
        "\n",
        "    for row, col in test_indices:\n",
        "        actual_ratings.append(user_item_matrix.iloc[row, col])\n",
        "        global_predictions.append(global_mean)\n",
        "\n",
        "        # User mean prediction\n",
        "        if user_means.iloc[row] > 0:\n",
        "            user_predictions.append(user_means.iloc[row])\n",
        "        else:\n",
        "            user_predictions.append(global_mean)\n",
        "\n",
        "        # Item mean prediction\n",
        "        if item_means.iloc[col] > 0:\n",
        "            item_predictions.append(item_means.iloc[col])\n",
        "        else:\n",
        "            item_predictions.append(global_mean)\n",
        "        returnVal = {\n",
        "          \"Global Mean RMSE\": np.sqrt(mean_squared_error(actual_ratings, global_predictions)),\n",
        "          \"User Mean RMSE\": np.sqrt(mean_squared_error(actual_ratings, user_predictions)),\n",
        "          \"Item Mean RMSE\": np.sqrt(mean_squared_error(actual_ratings, item_predictions)),\n",
        "        }\n",
        "\n",
        "    return returnVal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LM34Jnbqcps"
      },
      "outputs": [],
      "source": [
        "# Filter out books with less than 50 unique ratings\n",
        "filtered_books = filteredRatings.groupby('Book-Title').filter(lambda x: len(x) >= 50)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "filtered_indices = [\n",
        "    (row, col)\n",
        "    for row in range(userItem.shape[0])\n",
        "    for col in range(userItem.shape[1])\n",
        "    if userItem.iloc[row, col] > 0 and userItem.columns[col] in filtered_books['Book-Title'].values\n",
        "]\n",
        "\n",
        "test_sample_size = int(0.02 * len(filtered_indices))\n",
        "test_indices = np.random.choice(range(len(filtered_indices)), size=test_sample_size, replace=False)\n",
        "test_indices = [filtered_indices[idx] for idx in test_indices]\n",
        "\n",
        "train_data = userItem.copy()\n",
        "\n",
        "for row, col in test_indices:\n",
        "    train_data.iloc[row, col] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-deqG_UqdpX"
      },
      "outputs": [],
      "source": [
        "# Compute the global mean once\n",
        "global_mean = userItem.values[userItem > 0].mean()\n",
        "actual_ratings = [userItem.iloc[row, col] for row, col in test_indices]\n",
        "rmse_baseline = compare_baseline(userItem, test_indices)\n",
        "\n",
        "for baseline, rmse in rmse_baseline.items():\n",
        "    print(f\"{baseline}: {rmse:.4f}\")\n",
        "\n",
        "top_fifty = filteredRatings.groupby('Book-Title').count()['Book-Rating'] >=\n",
        "hybrid_predictions = []\n",
        "\n",
        "for row, col in test_indices:\n",
        "    user_id = userItem.columns[col]\n",
        "    book_title = userItem.index[row]\n",
        "\n",
        "    # Generate hybrid recommendations\n",
        "    hybrid_recommendation_scores = hybrid_recommendations(\n",
        "        user_id=user_id,\n",
        "        book_title=book_title,\n",
        "        content_weight=0.5,\n",
        "        collaborative_weight=0.5,\n",
        "        num_recommendations=10\n",
        "    )\n",
        "\n",
        "    predicted_score = next((score for book, score in hybrid_recommendation_scores if book == book_title), global_mean)\n",
        "    hybrid_predictions.append(predicted_score)\n",
        "\n",
        "# Compute RMSE for hybrid method\n",
        "hybrid_rmse = np.sqrt(mean_squared_error(actual_ratings, hybrid_predictions))\n",
        "print(\"Hybrid Method RMSE:\", hybrid_rmse)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}